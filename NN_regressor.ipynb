{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "css_file = './custom.css'\n",
    "HTML(open(css_file, \"r\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401 unused import\n",
    "\n",
    "#Adaption of James Loy's code for a single Node \n",
    "class Node:\n",
    "    def __init__(self, x, y, l=0.1):\n",
    "        self.input  = x\n",
    "        self.weight = np.random.rand() \n",
    "        self.bias   = np.random.rand()                 \n",
    "        self.y      = y\n",
    "        self.output = np.zeros(y.shape)\n",
    "        self.learning_rate = l\n",
    "    \n",
    "    def feedforward(self):\n",
    "        #Equal to predicting\n",
    "        self.output = np.dot(self.input.T, self.weight) + self.bias\n",
    "        \n",
    "        # Loss function\n",
    "        self.J = (np.sum((self.y - self.output.T) ** 2)) / len(self.input)\n",
    "    \n",
    "    def backprop(self):\n",
    "        # Then we want the partial derivative regarding weight and bias of this loss \n",
    "        weight_deriv = (np.sum(-2 * self.input * (self.y - self.output.T))) / len(self.input) \n",
    "        bias_deriv = (np.sum(-2 * (self.y - self.output.T))) / len(self.input)\n",
    "        \n",
    "        # update the weights with the derivative (slope) of the loss function\n",
    "        self.weight -= weight_deriv * self.learning_rate\n",
    "        self.bias -= bias_deriv * self.learning_rate\n",
    "\n",
    "    def train(self, n):\n",
    "        self.t_weights = []\n",
    "        self.t_biases = []\n",
    "        self.t_losses = []\n",
    "        for i in range(n):    \n",
    "            nn.feedforward()\n",
    "            self.t_weights.append(nn.weight)\n",
    "            self.t_biases.append(nn.bias)\n",
    "            self.t_losses.append(nn.J)\n",
    "            #print(f'Weight: {nn.weight} Bias: {nn.bias} Cost: {nn.J}')    \n",
    "            nn.backprop()\n",
    "        self.t_weights.append(nn.weight)\n",
    "        self.t_biases.append(nn.bias)\n",
    "        self.t_losses.append(nn.J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create regression data\n",
    "X, y, coef = make_regression(n_samples=20, n_features=1, noise=10, coef = True)\n",
    "#Include bias\n",
    "intercept = np.random.randint(-50, 50)\n",
    "y += intercept\n",
    "y = y.reshape(len(y),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = Node(X,y, 0.2)\n",
    "nn.train(200)\n",
    "    \n",
    "\n",
    "# Plot predicitons\n",
    "fig = plt.figure()\n",
    "y_pred = nn.output.T\n",
    "plt.scatter(X,y)\n",
    "plt.scatter(X,y_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Loss surface:\n",
    "def loss_plot(nn):\n",
    "    weights = np.linspace(coef - 1.5 * coef, coef + 1.5 * coef, 100)\n",
    "    biases = np.linspace(intercept - 1.5 * intercept, intercept + 1.5 * intercept , 100)\n",
    "    ww, bb = np.meshgrid(weights, biases)\n",
    "    \n",
    "    #Evaluate function at each point\n",
    "    losses = []\n",
    "    for bias in biases:\n",
    "        for weight in weights:\n",
    "            pred = np.dot(X.T, weight) + bias\n",
    "            loss = (np.sum((y - pred.T) ** 2)) / len(X)\n",
    "            losses.append(loss)\n",
    "    \n",
    "    losses = np.array(losses).reshape(100, 100)\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.gca(projection='3d')\n",
    "    ax.plot_surface(ww, bb, losses, linewidth=0, antialiased=False, cmap = cm.coolwarm, alpha = 0.5)\n",
    "    ax.scatter(nn.t_weights, nn.t_biases, nn.t_losses, c = 'r')\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "%matplotlib notebook\n",
    "loss_plot(nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
