# Neural-Net-Regressor
A little experiment with the simplest possible network, visualizing gradiant descent

I got inspired by [James Loy's NN tutorial](https://towardsdatascience.com/how-to-build-your-own-neural-network-from-scratch-in-python-68998a08e4f6) and adapted it into an even simpler network with only one node that performs a simple linear regression. 
The point for me was to visualize the loss surface corresponding to weight and bias of the single node and plotting the models learning steps. 

[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/bimtauer/Neural-Net-Regressor/master?filepath=https%3A%2F%2Fgithub.com%2Fbimtauer%2FNeural-Net-Regressor%2Fblob%2Fmaster%2FNN_regressor.ipynb)
